{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "- Timothy Carraher: Conceptualization, Writing – original draft\n",
    "- Mihir Vad: Background research, data curation, writing - original draft\n",
    "- Matthew Do: Background research , writing - original draft\n",
    "- Leah Maltezos: Background Research, writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are NYPD officers of certain races more likely to receive civilian complaints\n",
    "than expected based on their representation within the police force?\n",
    "\n",
    "Using NYPD personnel data and civilian complaint records, we will compare the proportion of complaints received by officers of each race to their proportion within the police officer population. This is a statistical inference task that will assess whether observed complaint distributions differ significantly from expected distributions proportionally. We will use simple regression and statistical tests like a chi-square test or regression complaint rate modeling to evaluate disproportionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The racial disparity in the police force is very clear in the United States, with many reports on\n",
    "how race influences police behavior and how civilians perceive law enforcement. Multiple\n",
    "studies have shown that communities of color, such as Black and Latino populations,\n",
    "experience disproportionate rates of police stops, use of force, and arrests.<a\n",
    "href=\"#fn1\"><sup>1</sup></a> However, there is not much focus on examining if officers of\n",
    "different racial backgrounds receive higher or lower rates of civilian complaints, and if complaint\n",
    "patterns might reflect biases in how the public perceives a police officer.\n",
    "\n",
    "The New York City Civilian Complaint Review Board keeps one of the largest databases of\n",
    "police misconduct complaints in the United States which contains detailed allegations against\n",
    "NYPD officers. Prior studies have found that officers with previous complaint histories are more\n",
    "likely to receive future complaints than those without a complaint history, suggesting that a small\n",
    "proportion of officers account for a disproportionate share of police misconduct.<a\n",
    "href=\"#fn2\"><sup>2</sup></a>\n",
    "\n",
    "Whether or not an officer's race influences complaint rates can reveal a complex dynamics of\n",
    "implicit bias and favoritism. Psychological research has shown that people of all races can have\n",
    "implicit biases that affect their judgments. <a href=\"#fn3\"><sup>3</sup></a> Some believe that\n",
    "racial compatitibility between officers and community members can improve trust and\n",
    "cooperation while others believe that training may be more determinative of officer behavior\n",
    "than their demographic characteristics.\n",
    "\n",
    "Another study finds that many major U.S. police forces do not hold a similar racial composition\n",
    "to the communities that they patrol in. The NYPD, despite being one of the more diverse police\n",
    "departments nationally, still shows disparities between officer demographics and the city's\n",
    "demographics.<a href=\"#fn4\"><sup>4</sup></a> Understanding whether officers of certain\n",
    "racial backgrounds receive complaints at higher rates than against others can shed light on\n",
    "potential biases in civilian comp\n",
    "\n",
    "References:\n",
    "\n",
    "<a name=\"fn1\">1.</a> Lofstrom, M., Hayes, J., Martin, B., & Premkumar, D. (Oct. 2021). Racial\n",
    "Disparities in Law Enforcement Stops. Public Policy Institute of California.\n",
    "https://www.ppic.org/publication/racial-disparities-in-law-enforcement-stops/\n",
    "\n",
    "<a name=\"fn2\">2.</a> Anyaso, H. (1 Aug. 2019) Police Officers’ Exposure to Peers Accused of\n",
    "Misconduct Shapes Their Subsequent Behavior.\n",
    "https://www.ipr.northwestern.edu/news/2019/papachristos-police-misconduct-study.html\n",
    "\n",
    "<a name=\"fn3\">3.</a> Carbado D. (May 2018) The Black Police: Policing Our Own\n",
    "https://harvardlawreview.org/print/vol-131/the-black-police-policing-our-own/\n",
    "\n",
    "<a name=\"fn4\">4.</a> Smith G., (3 Sept. 2019) Despite Diversity Gains, Top NYPD Ranks Fall\n",
    "Short of Reflecting Communities\n",
    "https://www.thecity.nyc/2019/09/03/despite-diversity-gains-top-nypd-ranks-fall-short-of-reflecting-communities/ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that Black and Hispanic NYPD officers will receive civilian complaints at higher\n",
    "rates than expected. On the other hand, white officers will receive complaints at rates lower than\n",
    "expected. This assumption is based on the fact that officers of color may possibly be\n",
    "disproportionately assigned to higher crime rate areas which will generally have more civilian\n",
    "interactions. These interactions would cause greater community tension and implicit biases can\n",
    "cause civilians to file complaints against more officers who are racial minorities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "\n",
    "#### Dataset #1: CCRB Complaints Dataset\n",
    "Source: Data Store Archive — ProPublica: https://projects.propublica.org/datastore/#civilian-complaints-against-new-york-city-police-officers  \n",
    "Observations: Approximately 33,358 closed complaints  \n",
    "Total Variables: 28  \n",
    "Purpose: Analyze complaint patterns against NYPD officers by officer race   \n",
    "Key Variables: Officer race, allegation type, incident date, disposition, and outcomes  \n",
    "Description: Allegation type is the type of discrimination faced by the victim(racism, homophobia, etc). Each disposition is categorized by substantiated (broke rules), exonerated (no rules broken), or unsubstantiated (not concluded) with an outcome being what the victim was charged with (arrested/not or summoned).  \n",
    "Problems: Missing entries for complainant ethnicity and/or gender  \n",
    "\n",
    "#### Dataset #2: NYPD Personnel Demographics\n",
    "Source: NYC Open Data: https://data.cityofnewyork.us/Public-Safety/NYPD-Personnel-Demographics/5vr7-5fki/about_data  \n",
    "Observations: 50,104 officers  \n",
    "Total Variables: 8  \n",
    "Purpose: Establish expected proportions for officer complaint analysis  \n",
    "Key Variables: Race, Rank, and YearsOnJob  \n",
    "Description: Each officer is listed with a given race, rank (officer, lieutenant, etc) and the number of years on the job.  \n",
    "Problems: In the application date for each officer, some of the dates are hidden.  \n",
    "\n",
    "#### Dataset #3: NYPD Arrests Data (Historic)\n",
    "Source: NYC Open Data:  https://data.cityofnewyork.us/Public-Safety/NYPD-Arrests-Data-Historic-/8h9b-rp9u/about_data   \n",
    "Observations: 5,986,025 arrest records  \n",
    "Total Variables: 19  \n",
    "Purpose: Analyze arrest patterns across racial groups across multiple years  \n",
    "Key Variables: PERP RACE, age group, arrest date, location, offense description, charge level  \n",
    "Description: Each arrest lists the perpetrator's race, age group(bins of <18, 18-24, 25-44, 44-65, 65+) arrest date and location(precinct, borough). For the arrest a description of what they did is given as well as what level they were charged with felony/misdemeanor. \n",
    "Problems: Missing Data points in various places  \n",
    "\n",
    "#### Dataset #4: NYC Population Demographics (ACS)\n",
    "Source: American Community Survey (ACS) 2012–2016: https://data.cityofnewyork.us/City-Government/Demographic-and-Housing-Profiles-by-Borough/cu9u-3r5e/about_data  \n",
    "Observations: Approximately 8.5 million residents   \n",
    "Total Variable: 6 regions (5 boroughs + NYC(in total))) x Approx. 90 categories for each  \n",
    "Purpose: Establish expected proportions for arrest analysis  \n",
    "Key Variables: White, Black, Asian, Hispanic, American Indian, Pacific Islander, Two or More   \n",
    "Description: Each borough and NYC as a whole has various race proportions and estimates for each race group and various subgroups. The key one important is the one listed for NYC for each race group above.  \n",
    "Problems: All of the listed proportions and estimates for each group aren't exact and are given with margins of error.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading NYPD_Personnel_Demographics.csv:   0%|          | 0.00/71.6k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  50%|█████     | 1/2 [00:00<00:00,  7.69it/s]                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: NYPD_Personnel_Demographics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading NYC_Population_Demographics.csv:   0%|          | 0.00/7.21k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:00<00:00, 11.02it/s]                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: NYC_Population_Demographics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group017_WI26/refs/heads/master/data/00-raw/NYPD_Personnel_Demographics_20260217.csv', 'filename':'NYPD_Personnel_Demographics.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group017_WI26/refs/heads/master/data/00-raw/NYC_Population_Demographics.csv', 'filename':'NYC_Population_Demographics.csv'}\n",
    "    #,{ 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCRB Complaints Dataset\n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYPD Personnel Demographics \n",
    "\n",
    "The NYPD Personnel Demographics dataset holds the demographic breakdown for active NYPD personnel. Each row lists an officer with a given race, rank (officer, lieutenant, etc), gender and the number of years on the job. This dataset has 50,104 observations with 8 variables.  \n",
    "\n",
    "The important variables we care about are Race, Rank, and YearsOnJob which all describe an officer's identity. Rank is a categorical variable which lists them as a Police Officer, Sergeant, etc as a hierarchy. YearsOnJob is a quantitative variable which lists the number of years they have been apart of the NYPD. These 2 variables are important because they represent an officer's experience which will influence assignments and complaint rates. This is because higher ranked officers are less likely to interact as much with civilians. The final key variable will be Race (Asian, Black, White, Hispanic, Native American, and White) will serve as a sort of baseline to compare racism with.   \n",
    "\n",
    "The purpose of this dataset is to establish expected proportions for officer complaint analysis. This will look to find if there is disproportionate representative of complaints in regards to NYPD proportions. The problems with this dataset is some appdate is hidden visually but this can be solved using pandas. The dataset also holds to NYPD classification of race groups making them rigid and won't represent an officer's identity with 100% accuracy. This dataset only includes active officers which doesn't line up with some of our other datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>MOS_Type</th>\n",
       "      <th>ranklit</th>\n",
       "      <th>sex</th>\n",
       "      <th>appdate</th>\n",
       "      <th>YearsOnJob</th>\n",
       "      <th>YearsOnJob (bins)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Male</td>\n",
       "      <td>02/28/1994</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Male</td>\n",
       "      <td>02/28/1994</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Male</td>\n",
       "      <td>01/13/1992</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Male</td>\n",
       "      <td>02/28/1994</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Male</td>\n",
       "      <td>07/18/1996</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50099</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Detective</td>\n",
       "      <td>Male</td>\n",
       "      <td>12/29/2021</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50100</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Detective</td>\n",
       "      <td>Male</td>\n",
       "      <td>01/10/2018</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50101</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Detective</td>\n",
       "      <td>Male</td>\n",
       "      <td>04/13/2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50102</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Detective</td>\n",
       "      <td>Male</td>\n",
       "      <td>07/13/2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50103</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Detective</td>\n",
       "      <td>Male</td>\n",
       "      <td>12/08/1997</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender      Race MOS_Type         ranklit   sex     appdate  YearsOnJob  \\\n",
       "0       Male  Hispanic  Uniform  Police Officer  Male  02/28/1994          31   \n",
       "1       Male  Hispanic  Uniform  Police Officer  Male  02/28/1994          31   \n",
       "2       Male  Hispanic  Uniform  Police Officer  Male  01/13/1992          34   \n",
       "3       Male  Hispanic  Uniform  Police Officer  Male  02/28/1994          31   \n",
       "4       Male  Hispanic  Uniform  Police Officer  Male  07/18/1996          29   \n",
       "...      ...       ...      ...             ...   ...         ...         ...   \n",
       "50099   Male     White  Uniform       Detective  Male  12/29/2021           4   \n",
       "50100   Male     White  Uniform       Detective  Male  01/10/2018           8   \n",
       "50101   Male     White  Uniform       Detective  Male  04/13/2022           3   \n",
       "50102   Male     White  Uniform       Detective  Male  07/13/2022           3   \n",
       "50103   Male     White  Uniform       Detective  Male  12/08/1997          28   \n",
       "\n",
       "       YearsOnJob (bins)  \n",
       "0                     30  \n",
       "1                     30  \n",
       "2                     30  \n",
       "3                     30  \n",
       "4                     25  \n",
       "...                  ...  \n",
       "50099                  0  \n",
       "50100                  5  \n",
       "50101                  0  \n",
       "50102                  0  \n",
       "50103                 25  \n",
       "\n",
       "[50104 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "df = pd.read_csv('data/00-raw/NYPD_Personnel_Demographics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50104, 8)\n",
      "\n",
      "Columns: Index(['Gender', 'Race', 'MOS_Type', 'ranklit', 'sex', 'appdate', 'YearsOnJob',\n",
      "       'YearsOnJob (bins)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Count: Gender               0\n",
      "Race                 0\n",
      "MOS_Type             0\n",
      "ranklit              0\n",
      "sex                  0\n",
      "appdate              0\n",
      "YearsOnJob           0\n",
      "YearsOnJob (bins)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missingness check\n",
    "missing_counts = df.isna().sum()\n",
    "print(\"\\nMissing Count:\", missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Validity Check\n",
    "if 'YearsOnJob' in df.columns:\n",
    "    print(\"invalid entries:\", len(df[(df['YearsOnJob'] < 0) | (df['YearsOnJob'] > 60)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned shape: (50104, 8)\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning (none detected)\n",
    "df.drop(columns = 'appdate')\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "df[cat_cols] = df[cat_cols].fillna('Unknown')\n",
    "\n",
    "for col in df.select_dtypes(include='number').columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "print(\"Cleaned shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50104.000000\n",
       "mean        10.179746\n",
       "std          8.287782\n",
       "min          0.000000\n",
       "25%          3.000000\n",
       "50%          9.000000\n",
       "75%         16.000000\n",
       "max         52.000000\n",
       "Name: yearsonjob, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>mos_type</th>\n",
       "      <th>ranklit</th>\n",
       "      <th>sex</th>\n",
       "      <th>appdate</th>\n",
       "      <th>yearsonjob</th>\n",
       "      <th>yearsonjob_(bins)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>12965</td>\n",
       "      <td>12965</td>\n",
       "      <td>12965</td>\n",
       "      <td>12965</td>\n",
       "      <td>12965</td>\n",
       "      <td>12965</td>\n",
       "      <td>12965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>15166</td>\n",
       "      <td>15166</td>\n",
       "      <td>15166</td>\n",
       "      <td>15166</td>\n",
       "      <td>15166</td>\n",
       "      <td>15166</td>\n",
       "      <td>15166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native American</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>14953</td>\n",
       "      <td>14953</td>\n",
       "      <td>14953</td>\n",
       "      <td>14953</td>\n",
       "      <td>14953</td>\n",
       "      <td>14953</td>\n",
       "      <td>14953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gender  mos_type  ranklit    sex  appdate  yearsonjob  \\\n",
       "race                                                                     \n",
       "Asian              6951      6951     6951   6951     6951        6951   \n",
       "Black             12965     12965    12965  12965    12965       12965   \n",
       "Hispanic          15166     15166    15166  15166    15166       15166   \n",
       "Native American      69        69       69     69       69          69   \n",
       "White             14953     14953    14953  14953    14953       14953   \n",
       "\n",
       "                 yearsonjob_(bins)  \n",
       "race                                \n",
       "Asian                         6951  \n",
       "Black                        12965  \n",
       "Hispanic                     15166  \n",
       "Native American                 69  \n",
       "White                        14953  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Summary Stats\n",
    "display(df['yearsonjob'].describe())\n",
    "df.groupby('race').count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYPD Arrests Data (Historic) \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/00-raw/nypd_personnel_demographics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/00-raw/nypd_personnel_demographics.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/00-raw/nypd_personnel_demographics.csv'"
     ]
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "df = pd.read_csv('data/00-raw/nypd_personnel_demographics.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC Population Demographics (ACS)\n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (tidy NYC-only): (84, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>nyc_Estimate</th>\n",
       "      <th>nyc_Margin_of_Error</th>\n",
       "      <th>nyc_Percent</th>\n",
       "      <th>nyc_Percent_MoE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total population</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8461961.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8461961.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4033736.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4428225.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Under 5 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555383.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5 to 9 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487643.0</td>\n",
       "      <td>3642.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10 to 14 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>466493.0</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15 to 19 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>479928.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20 to 24 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620742.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25 to 34 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1497751.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35 to 44 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174805.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45 to 54 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1111690.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>55 to 59 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511012.0</td>\n",
       "      <td>3665.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Subject Subcategory  nyc_Estimate  nyc_Margin_of_Error  \\\n",
       "6       Total population         NaN     8461961.0                  NaN   \n",
       "7                   Male         NaN     4033736.0                378.0   \n",
       "8                 Female         NaN     4428225.0                378.0   \n",
       "10         Under 5 years         NaN      555383.0                358.0   \n",
       "11          5 to 9 years         NaN      487643.0               3642.0   \n",
       "12        10 to 14 years         NaN      466493.0               3746.0   \n",
       "13        15 to 19 years         NaN      479928.0                777.0   \n",
       "14        20 to 24 years         NaN      620742.0                789.0   \n",
       "15        25 to 34 years         NaN     1497751.0                457.0   \n",
       "16        35 to 44 years         NaN     1174805.0                447.0   \n",
       "17        45 to 54 years         NaN     1111690.0                403.0   \n",
       "18        55 to 59 years         NaN      511012.0               3665.0   \n",
       "\n",
       "    nyc_Percent  nyc_Percent_MoE  \n",
       "6     8461961.0              NaN  \n",
       "7          47.7              0.1  \n",
       "8          52.3              0.1  \n",
       "10          6.6              0.1  \n",
       "11          5.8              0.1  \n",
       "12          5.5              0.1  \n",
       "13          5.7              0.1  \n",
       "14          7.3              0.1  \n",
       "15         17.7              0.1  \n",
       "16         13.9              0.1  \n",
       "17         13.1              0.1  \n",
       "18          6.0              0.1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('data/00-raw/NYC_Population_Demographics.csv', header=None)\n",
    "\n",
    "regions = ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island', 'New York City']\n",
    "metrics = ['Estimate', 'Margin of Error', 'Percent', 'Percent MoE']\n",
    "col_names = ['Subject', 'Subcategory']\n",
    "for r in regions:\n",
    "    for m in metrics:\n",
    "        col_names.append(f'{r}_{m}')\n",
    "df_acs = raw.iloc[5:].copy()\n",
    "df_acs.columns = col_names[:df_acs.shape[1]]\n",
    "df_acs['Subject'] = df_acs['Subject'].ffill()\n",
    "\n",
    "nyc_cols = [c for c in df_acs.columns if c.startswith('New York City_')]\n",
    "def to_numeric_clean(s):\n",
    "    v = str(s).strip().replace(',', '').replace('+/-', '').replace('%', '').replace('*****', '').replace('(X)', '')\n",
    "    try:\n",
    "        return pd.to_numeric(v) if v and v != 'nan' else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "for c in nyc_cols:\n",
    "    df_acs[c] = df_acs[c].apply(to_numeric_clean)\n",
    "df_acs = df_acs[df_acs[nyc_cols].notna().any(axis=1)]\n",
    "\n",
    "df_nyc = df_acs[['Subject', 'Subcategory'] + nyc_cols].copy()\n",
    "df_nyc = df_nyc.rename(columns={c: c.replace('New York City_', 'nyc_').replace(' ', '_') for c in nyc_cols})\n",
    "\n",
    "\n",
    "print(\"Shape (tidy NYC-only):\", df_nyc.shape)\n",
    "df_nyc.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing counts per column:\n",
      " Subject                 0\n",
      "Subcategory            84\n",
      "nyc_Estimate            0\n",
      "nyc_Margin_of_Error     6\n",
      "nyc_Percent             2\n",
      "nyc_Percent_MoE        11\n",
      "dtype: int64\n",
      "\n",
      "Rows with any missing: 84\n"
     ]
    }
   ],
   "source": [
    "# Missingness check\n",
    "missing = df_nyc.isna().sum()\n",
    "print(\"Missing counts per column:\\n\", missing)\n",
    "print(\"\\nRows with any missing:\", df_nyc.isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyc_Estimate range: 35.9 – 8461961.0\n",
      "nyc_Percent range: 0.0 – 8461961.0\n",
      "Rows with percent outside [0,100]: 7\n",
      "Rows with negative estimate: 0\n"
     ]
    }
   ],
   "source": [
    "# Outliers\n",
    "print(\"nyc_Estimate range:\", df_nyc['nyc_Estimate'].min(), \"–\", df_nyc['nyc_Estimate'].max())\n",
    "print(\"nyc_Percent range:\", df_nyc['nyc_Percent'].min(), \"–\", df_nyc['nyc_Percent'].max())\n",
    "\n",
    "outlier = df_nyc[(df_nyc['nyc_Percent'].notna()) & ((df_nyc['nyc_Percent'] < 0) | (df_nyc['nyc_Percent'] > 100))]\n",
    "print(\"Rows with percent outside [0,100]:\", len(outlier))\n",
    "outlier_est = df_nyc[(df_nyc['nyc_Estimate'].notna()) & (df_nyc['nyc_Estimate'] < 0)]\n",
    "print(\"Rows with negative estimate:\", len(outlier_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned shape: (84, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>nyc_Estimate</th>\n",
       "      <th>nyc_Margin_of_Error</th>\n",
       "      <th>nyc_Percent</th>\n",
       "      <th>nyc_Percent_MoE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total population</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8461961.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8461961.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4033736.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4428225.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Under 5 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555383.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5 to 9 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487643.0</td>\n",
       "      <td>3642.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Subject Subcategory  nyc_Estimate  nyc_Margin_of_Error  \\\n",
       "6       Total population         NaN     8461961.0                  NaN   \n",
       "7                   Male         NaN     4033736.0                378.0   \n",
       "8                 Female         NaN     4428225.0                378.0   \n",
       "10         Under 5 years         NaN      555383.0                358.0   \n",
       "11          5 to 9 years         NaN      487643.0               3642.0   \n",
       "\n",
       "    nyc_Percent  nyc_Percent_MoE  \n",
       "6     8461961.0              NaN  \n",
       "7          47.7              0.1  \n",
       "8          52.3              0.1  \n",
       "10          6.6              0.1  \n",
       "11          5.8              0.1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean\n",
    "numeric_cols = ['nyc_Estimate', 'nyc_Margin_of_Error', 'nyc_Percent', 'nyc_Percent_MoE']\n",
    "df_clean = df_nyc[df_nyc[numeric_cols].notna().any(axis=1)].copy()\n",
    "\n",
    "print(\"Cleaned shape:\", df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to 02-processed \n",
    "df_clean.to_csv(\"data/02-processed/NYC_Population_Demographics.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection \n",
    "- [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "Our project uses publicly available government and research datasets from sources such as NYC Open Data rather than collecting data directly from individuals. Because we are not interacting with individuals or collecting personal responses, traditional informed consent does not apply. However, we will still use the data responsibly and follow any data use guidelines provided by the original data sources. We will also be careful to present results in ways that do not harm individuals or communities.\n",
    "\n",
    "- [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "There may be bias in civilian complaint data because not all misconduct gets reported. For example some people may not file complaints if they don't trust the police, don't know how to report, or think it won't make a difference. These are just some of the many reasons. Reporting may also vary between different communities. Because of this, complaint numbers don't perfectly show officer behavior. In our project, we will keep this limitation in mind and avoid treating complaint counts as direct proot of misconduct.\n",
    "\n",
    "- [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "We will only use data that does not include personal identifying information or is grouped together so individual officers cannot be identified. For example we will not use officer names, badge numbers, or other identifying details. All results will be reported in group or summary form instead of focusing on individuals. This will help protect privacy and reduces the risk of someone being singled out or misidentified. We want to make sure our analysis focuses on overall trends rather than specific people.\n",
    "       \n",
    "- [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "Because this project studies racial differences, it is important to carefully interpret results and avoid reinforcing stereotypes. We will be sure to frame findings as structural or systemic patterns rather than individual blame. We will also emphasize limitations of the data when presenting results. We will also be careful with how we explain our findings so they are not taken out of context. Our goal is to help people understand patterns in the data, not make assumptions about individuals or groups.\n",
    "\n",
    "### B. Data Storage\n",
    "- [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "All the datasets we used are publicly available and will be stored securely in password protected university environments such as  \n",
    "Datahub. Access will be limited among our project group only. Even though the data is public, we will still handle it responsibly and avoid storing unnecessary copies. Project files will only be shared within our group.\n",
    "\n",
    "- [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "- [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "Data will only be stored for the duration of the course project. After the project is completed, local copies will be deleted and only final analysis outputs will remain in the project repository.\n",
    "\n",
    "### C. Analysis\n",
    "- [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "Our analysis focuses on complaint data and officer demographics, which does not capture the full social and historical context of policing. We will be sure to acknowledge that complaint data does not fully represent all community experiences and will avoid making broad claims about behavior or intent.\n",
    "\n",
    "- [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "Complaint data may reflect reporting bias, systemic bias, and uneven enforcement patterns. Not all misconduct is reported, and reporting rates may vary across different communities or neighborhoods. Because of this, complaint numbers may not fully represent actual behavior or incidents. We will test distributions carefully and clearly separate correlation from causation when interpreting results. We will also acknowledge these limitations when presenting our findings.\n",
    "       \n",
    "- [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "All visualizations and statistics will be presented clearly and without exaggeration. We will avoid making graphs that could be misleading or confusing to readers. We will also not be selective of our data in which we only show the data that supports our expectations. We will also make sure to explain our results carefully and avoid making broad conclusions that are not supported by the data.\n",
    "\n",
    "- [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "No personally identifiable information will be shown in visualizations or shared outputs. Results will only be shown as group data. This means we will focus on trends across groups rather than individual officers. This helps protect privacy and reduces the risk of misidentifying or targeting individuals.\n",
    "\n",
    "- [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "All code, data cleaning steps, and analysis methods will be documented in the notebook to ensure reproducibility. This allows others to understand how results were created and verify our work if needed. Keeping clear records also helps prevent mistakes and improves transparency in our research process.\n",
    "\n",
    "### D. Modeling\n",
    "- [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "We will check if any variables might indirectly reflect race. If we notice this, we will think carefully about whether we should use that variable or explain why it is needed. Our goal is to avoid results that could be unfair or misleading If we notice a variable may indirectly reflect sensitive demographic information, we will reconsider using it or explain why it is necessary.  \n",
    "Our ultimate goal is to avoid creating unfair or misleading results.\n",
    "\n",
    "- [ ] **D.2 Fairness across groups**  \n",
    "- [ ] **D.3 Metric selection**  \n",
    "- [ ] **D.4 Explainability**  \n",
    "- [X] **D.5 Communicate limitations**\n",
    "\n",
    "We will clearly explain the limits of complaint data and avoid presenting results as proof of individual officer behavior or intent. Complaint data shows reported incidents, not confirmed misconduct. We will also explain that just because two things are related does not mean one causes the other.\n",
    "\n",
    "### E. Deployment\n",
    "- [ ] **E.1 Monitoring and evaluation**  \n",
    "- [ ] **E.2 Redress**  \n",
    "- [ ] **E.3 Roll back**  \n",
    "- [ ] **E.4 Unintended use**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Team Expectation 1*  Respectful and timely communciation via text group chat\n",
    "* *Team Expectation 2*  Clear delegation of roles and accountability if said roles are not completed well or in a timely manner\n",
    "* *Team Expecation 3*  Planning ahead of time; all team members read the assignment and understand what is being asked and if not don't wait till last minute\n",
    "* *Team Expecation 4*  If conflict arises deal with it in a democratic and respectful manner\n",
    "* *Team Expecation 5*  Constructive feedback, not unconstructive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Meeting Time | Tasks | Discuss at Meeting |\n",
    "|-------------|--------------|-------|-------------------|\n",
    "| 2/18 | 12 PM | Finalize and turn in Data Checkpoint | Finish Tasks |\n",
    "| 2/24 | 6 PM | Work on analysis and visualizations; prepare EDA | Finish Tasks |\n",
    "| 3/4 | 12 PM | Finalize and turn in EDA Checkpoint | Finish Tasks |\n",
    "| 3/10 | 6 PM | Discuss final roles and visualization changes | Finish Tasks |\n",
    "| 3/13 | 6 PM | Final touches and problem fixing | Finish Tasks |\n",
    "| 3/18 | Before 11:59 PM | Turn in Final Project & Surveys | Finish Tasks |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
